{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import cifar10,fashion_mnist\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.metrics import confusion_matrix , classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainy), (testX, testy) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TrainX: (60000, 28, 28)\n",
      "Shape of Trainy: (60000,)\n",
      "Shape of TestX: (10000, 28, 28)\n",
      "Shape of Testy: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TrainX:\", trainX.shape)\n",
    "print(\"Shape of Trainy:\", trainy.shape)\n",
    "print(\"Shape of TestX:\", testX.shape)\n",
    "print(\"Shape of Testy:\", testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape(len(trainX), 28,28)\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testX = testX.reshape(len(testX), 28,28)\n",
    "testy = testy.reshape(len(testy), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TrainX: (60000, 28, 28)\n",
      "Shape of Trainy: (60000, 1)\n",
      "Shape of TestX: (10000, 28, 28)\n",
      "Shape of Testy: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TrainX:\", trainX.shape)\n",
    "print(\"Shape of Trainy:\", trainy.shape)\n",
    "print(\"Shape of TestX:\", testX.shape)\n",
    "print(\"Shape of Testy:\", testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  41, 188, 103,\n",
       "         54,  48,  43,  87, 168, 133,  16,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,  49, 136, 219, 216, 228, 236,\n",
       "        255, 255, 255, 255, 217, 215, 254, 231, 160,  45,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  14, 176, 222, 224, 212, 203, 198, 196,\n",
       "        200, 215, 204, 202, 201, 201, 201, 209, 218, 224, 164,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 188, 219, 200, 198, 202, 198, 199, 199,\n",
       "        201, 196, 198, 198, 200, 200, 200, 200, 201, 200, 225,  41,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  51, 219, 199, 203, 203, 212, 238, 248, 250,\n",
       "        245, 249, 246, 247, 252, 248, 235, 207, 203, 203, 222, 140,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 116, 226, 206, 204, 207, 204, 101,  75,  47,\n",
       "         73,  48,  50,  45,  51,  63, 113, 222, 202, 206, 220, 224,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 200, 222, 209, 203, 215, 200,   0,  70,  98,\n",
       "          0, 103,  59,  68,  71,  49,   0, 219, 206, 214, 210, 250,  38,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 247, 218, 212, 210, 215, 214,   0, 254, 243,\n",
       "        139, 255, 174, 251, 255, 205,   0, 215, 217, 214, 208, 220,  95,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  45, 226, 214, 214, 215, 224, 205,   0,  42,  35,\n",
       "         60,  16,  17,  12,  13,  70,   0, 189, 216, 212, 206, 212, 156,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 164, 235, 214, 211, 220, 216, 201,  52,  71,  89,\n",
       "         94,  83,  78,  70,  76,  92,  87, 206, 207, 222, 213, 219, 208,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 106, 187, 223, 237, 248, 211, 198, 252, 250, 248,\n",
       "        245, 248, 252, 253, 250, 252, 239, 201, 212, 225, 215, 193, 113,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  17,  54, 159, 222, 193, 208, 192, 197,\n",
       "        200, 200, 200, 200, 201, 203, 195, 210, 165,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  47, 225, 192, 214, 203, 206,\n",
       "        204, 204, 205, 206, 204, 212, 197, 218, 107,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   1,   6,   0,  46, 212, 195, 212, 202, 206,\n",
       "        205, 204, 205, 206, 204, 212, 200, 218,  91,   0,   3,   1,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,  11, 197, 199, 205, 202, 205,\n",
       "        206, 204, 205, 207, 204, 205, 205, 218,  77,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0,   2, 191, 198, 201, 205, 206,\n",
       "        205, 205, 206, 209, 206, 199, 209, 219,  74,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   0, 188, 197, 200, 207, 207,\n",
       "        204, 207, 207, 210, 208, 198, 207, 221,  72,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   0, 215, 198, 203, 206, 208,\n",
       "        205, 207, 207, 210, 208, 200, 202, 222,  75,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 212, 198, 209, 206, 209,\n",
       "        206, 208, 207, 211, 206, 205, 198, 221,  80,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 201, 205, 208, 207,\n",
       "        205, 211, 205, 210, 210, 209, 195, 221,  96,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 202, 201, 205, 209, 207,\n",
       "        205, 213, 206, 210, 209, 210, 194, 217, 105,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 204, 205, 208, 207,\n",
       "        205, 215, 207, 210, 208, 211, 193, 213, 115,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 204, 207, 207, 208, 206,\n",
       "        206, 215, 210, 210, 207, 212, 195, 210, 118,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 208, 208, 208, 204,\n",
       "        207, 212, 212, 210, 207, 211, 196, 207, 121,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 210, 207, 208, 206,\n",
       "        209, 213, 212, 211, 207, 210, 197, 207, 124,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 172, 210, 203, 201, 199,\n",
       "        204, 207, 205, 204, 201, 205, 197, 206, 127,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 188, 221, 214, 234, 236,\n",
       "        238, 244, 244, 244, 240, 243, 214, 224, 162,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 139, 146, 130, 135, 135,\n",
       "        137, 125, 124, 125, 121, 119, 114, 130,  76,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX/255.0\n",
    "testX = testX/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16078431, 0.7372549 , 0.40392157, 0.21176471, 0.18823529,\n",
       "        0.16862745, 0.34117647, 0.65882353, 0.52156863, 0.0627451 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.53333333, 0.85882353,\n",
       "        0.84705882, 0.89411765, 0.9254902 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.85098039, 0.84313725, 0.99607843,\n",
       "        0.90588235, 0.62745098, 0.17647059, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.05490196, 0.69019608, 0.87058824, 0.87843137, 0.83137255,\n",
       "        0.79607843, 0.77647059, 0.76862745, 0.78431373, 0.84313725,\n",
       "        0.8       , 0.79215686, 0.78823529, 0.78823529, 0.78823529,\n",
       "        0.81960784, 0.85490196, 0.87843137, 0.64313725, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.7372549 , 0.85882353, 0.78431373, 0.77647059, 0.79215686,\n",
       "        0.77647059, 0.78039216, 0.78039216, 0.78823529, 0.76862745,\n",
       "        0.77647059, 0.77647059, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78823529, 0.78431373, 0.88235294, 0.16078431,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.2       ,\n",
       "        0.85882353, 0.78039216, 0.79607843, 0.79607843, 0.83137255,\n",
       "        0.93333333, 0.97254902, 0.98039216, 0.96078431, 0.97647059,\n",
       "        0.96470588, 0.96862745, 0.98823529, 0.97254902, 0.92156863,\n",
       "        0.81176471, 0.79607843, 0.79607843, 0.87058824, 0.54901961,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.45490196,\n",
       "        0.88627451, 0.80784314, 0.8       , 0.81176471, 0.8       ,\n",
       "        0.39607843, 0.29411765, 0.18431373, 0.28627451, 0.18823529,\n",
       "        0.19607843, 0.17647059, 0.2       , 0.24705882, 0.44313725,\n",
       "        0.87058824, 0.79215686, 0.80784314, 0.8627451 , 0.87843137,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.78431373,\n",
       "        0.87058824, 0.81960784, 0.79607843, 0.84313725, 0.78431373,\n",
       "        0.        , 0.2745098 , 0.38431373, 0.        , 0.40392157,\n",
       "        0.23137255, 0.26666667, 0.27843137, 0.19215686, 0.        ,\n",
       "        0.85882353, 0.80784314, 0.83921569, 0.82352941, 0.98039216,\n",
       "        0.14901961, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.96862745,\n",
       "        0.85490196, 0.83137255, 0.82352941, 0.84313725, 0.83921569,\n",
       "        0.        , 0.99607843, 0.95294118, 0.54509804, 1.        ,\n",
       "        0.68235294, 0.98431373, 1.        , 0.80392157, 0.        ,\n",
       "        0.84313725, 0.85098039, 0.83921569, 0.81568627, 0.8627451 ,\n",
       "        0.37254902, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.17647059, 0.88627451,\n",
       "        0.83921569, 0.83921569, 0.84313725, 0.87843137, 0.80392157,\n",
       "        0.        , 0.16470588, 0.1372549 , 0.23529412, 0.0627451 ,\n",
       "        0.06666667, 0.04705882, 0.05098039, 0.2745098 , 0.        ,\n",
       "        0.74117647, 0.84705882, 0.83137255, 0.80784314, 0.83137255,\n",
       "        0.61176471, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.64313725, 0.92156863,\n",
       "        0.83921569, 0.82745098, 0.8627451 , 0.84705882, 0.78823529,\n",
       "        0.20392157, 0.27843137, 0.34901961, 0.36862745, 0.3254902 ,\n",
       "        0.30588235, 0.2745098 , 0.29803922, 0.36078431, 0.34117647,\n",
       "        0.80784314, 0.81176471, 0.87058824, 0.83529412, 0.85882353,\n",
       "        0.81568627, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.41568627, 0.73333333,\n",
       "        0.8745098 , 0.92941176, 0.97254902, 0.82745098, 0.77647059,\n",
       "        0.98823529, 0.98039216, 0.97254902, 0.96078431, 0.97254902,\n",
       "        0.98823529, 0.99215686, 0.98039216, 0.98823529, 0.9372549 ,\n",
       "        0.78823529, 0.83137255, 0.88235294, 0.84313725, 0.75686275,\n",
       "        0.44313725, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06666667, 0.21176471, 0.62352941, 0.87058824, 0.75686275,\n",
       "        0.81568627, 0.75294118, 0.77254902, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78823529, 0.79607843, 0.76470588,\n",
       "        0.82352941, 0.64705882, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18431373, 0.88235294, 0.75294118,\n",
       "        0.83921569, 0.79607843, 0.80784314, 0.8       , 0.8       ,\n",
       "        0.80392157, 0.80784314, 0.8       , 0.83137255, 0.77254902,\n",
       "        0.85490196, 0.41960784, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.02352941, 0.        , 0.18039216, 0.83137255, 0.76470588,\n",
       "        0.83137255, 0.79215686, 0.80784314, 0.80392157, 0.8       ,\n",
       "        0.80392157, 0.80784314, 0.8       , 0.83137255, 0.78431373,\n",
       "        0.85490196, 0.35686275, 0.        , 0.01176471, 0.00392157,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.04313725, 0.77254902, 0.78039216,\n",
       "        0.80392157, 0.79215686, 0.80392157, 0.80784314, 0.8       ,\n",
       "        0.80392157, 0.81176471, 0.8       , 0.80392157, 0.80392157,\n",
       "        0.85490196, 0.30196078, 0.        , 0.01960784, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01176471, 0.        , 0.00784314, 0.74901961, 0.77647059,\n",
       "        0.78823529, 0.80392157, 0.80784314, 0.80392157, 0.80392157,\n",
       "        0.80784314, 0.81960784, 0.80784314, 0.78039216, 0.81960784,\n",
       "        0.85882353, 0.29019608, 0.        , 0.01960784, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.        , 0.        , 0.7372549 , 0.77254902,\n",
       "        0.78431373, 0.81176471, 0.81176471, 0.8       , 0.81176471,\n",
       "        0.81176471, 0.82352941, 0.81568627, 0.77647059, 0.81176471,\n",
       "        0.86666667, 0.28235294, 0.        , 0.01568627, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.        , 0.        , 0.84313725, 0.77647059,\n",
       "        0.79607843, 0.80784314, 0.81568627, 0.80392157, 0.81176471,\n",
       "        0.81176471, 0.82352941, 0.81568627, 0.78431373, 0.79215686,\n",
       "        0.87058824, 0.29411765, 0.        , 0.01568627, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.83137255, 0.77647059,\n",
       "        0.81960784, 0.80784314, 0.81960784, 0.80784314, 0.81568627,\n",
       "        0.81176471, 0.82745098, 0.80784314, 0.80392157, 0.77647059,\n",
       "        0.86666667, 0.31372549, 0.        , 0.01176471, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.8       , 0.78823529,\n",
       "        0.80392157, 0.81568627, 0.81176471, 0.80392157, 0.82745098,\n",
       "        0.80392157, 0.82352941, 0.82352941, 0.81960784, 0.76470588,\n",
       "        0.86666667, 0.37647059, 0.        , 0.01176471, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.79215686, 0.78823529,\n",
       "        0.80392157, 0.81960784, 0.81176471, 0.80392157, 0.83529412,\n",
       "        0.80784314, 0.82352941, 0.81960784, 0.82352941, 0.76078431,\n",
       "        0.85098039, 0.41176471, 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.8       , 0.8       ,\n",
       "        0.80392157, 0.81568627, 0.81176471, 0.80392157, 0.84313725,\n",
       "        0.81176471, 0.82352941, 0.81568627, 0.82745098, 0.75686275,\n",
       "        0.83529412, 0.45098039, 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.8       , 0.81176471,\n",
       "        0.81176471, 0.81568627, 0.80784314, 0.80784314, 0.84313725,\n",
       "        0.82352941, 0.82352941, 0.81176471, 0.83137255, 0.76470588,\n",
       "        0.82352941, 0.4627451 , 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.77647059, 0.81568627,\n",
       "        0.81568627, 0.81568627, 0.8       , 0.81176471, 0.83137255,\n",
       "        0.83137255, 0.82352941, 0.81176471, 0.82745098, 0.76862745,\n",
       "        0.81176471, 0.4745098 , 0.        , 0.00392157, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.77647059, 0.82352941,\n",
       "        0.81176471, 0.81568627, 0.80784314, 0.81960784, 0.83529412,\n",
       "        0.83137255, 0.82745098, 0.81176471, 0.82352941, 0.77254902,\n",
       "        0.81176471, 0.48627451, 0.        , 0.00392157, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.6745098 , 0.82352941,\n",
       "        0.79607843, 0.78823529, 0.78039216, 0.8       , 0.81176471,\n",
       "        0.80392157, 0.8       , 0.78823529, 0.80392157, 0.77254902,\n",
       "        0.80784314, 0.49803922, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.7372549 , 0.86666667,\n",
       "        0.83921569, 0.91764706, 0.9254902 , 0.93333333, 0.95686275,\n",
       "        0.95686275, 0.95686275, 0.94117647, 0.95294118, 0.83921569,\n",
       "        0.87843137, 0.63529412, 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.54509804, 0.57254902,\n",
       "        0.50980392, 0.52941176, 0.52941176, 0.5372549 , 0.49019608,\n",
       "        0.48627451, 0.49019608, 0.4745098 , 0.46666667, 0.44705882,\n",
       "        0.50980392, 0.29803922, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\", \"Coat\",\"Sandal\",\"Shirt\", \"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(trainX))\n",
    "plt.imshow(trainX[idx,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (1,1), padding = 'valid',activation = 'relu',input_shape = [28,28,1]), # 1st Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 128 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'relu',input_shape = [28,28,1]), # 2nd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'relu',input_shape = [28,28,1]), # 3rd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(units = 128,activation = 'relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 256,activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units = 256,activation = 'relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 128,activation = 'relu'),\n",
    "        Dropout(0.10),\n",
    "        Dense(units = 10,activation = 'softmax')  \n",
    "                        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 13, 13, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 3, 3, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 2, 2, 64)          73792     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 1, 1, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 289,610\n",
      "Trainable params: 289,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 64s 543ms/step - loss: 0.8887 - accuracy: 0.6422 - val_loss: 0.5730 - val_accuracy: 0.7808\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 66s 560ms/step - loss: 0.5379 - accuracy: 0.7976 - val_loss: 0.4936 - val_accuracy: 0.7984\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 65s 551ms/step - loss: 0.4454 - accuracy: 0.8366 - val_loss: 0.4037 - val_accuracy: 0.8491\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 65s 546ms/step - loss: 0.3857 - accuracy: 0.8630 - val_loss: 0.3709 - val_accuracy: 0.8656\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 66s 558ms/step - loss: 0.3451 - accuracy: 0.8770 - val_loss: 0.3172 - val_accuracy: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286328740a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainy,epochs = 5,batch_size = 512,verbose = 1, validation_data=(testX,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3172 - accuracy: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31716692447662354, 0.8873000144958496]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Different Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 137s 1s/step - loss: 1.0991 - accuracy: 0.5735 - val_loss: 0.6424 - val_accuracy: 0.7588\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 126s 1s/step - loss: 0.5752 - accuracy: 0.7788 - val_loss: 0.4974 - val_accuracy: 0.8099\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 130s 1s/step - loss: 0.4816 - accuracy: 0.8192 - val_loss: 0.4476 - val_accuracy: 0.8297\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 126s 1s/step - loss: 0.4202 - accuracy: 0.8443 - val_loss: 0.3952 - val_accuracy: 0.8524\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 126s 1s/step - loss: 0.3830 - accuracy: 0.8584 - val_loss: 0.3700 - val_accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2863497ddc0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (1,1), padding = 'valid',activation = 'gelu' ,input_shape = [28,28,1]), # 1st Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 128 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'gelu' ,input_shape = [28,28,1]), # 2nd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'gelu' ,input_shape = [28,28,1]), # 3rd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(units = 128,activation = 'gelu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 256,activation = 'gelu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units = 256,activation = 'gelu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 128,activation = 'gelu'),\n",
    "        Dropout(0.10),\n",
    "        Dense(units = 10,activation = 'softmax')  \n",
    "                        \n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainX,trainy,epochs = 5,batch_size = 512,verbose = 1, validation_data=(testX,testy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3700 - accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36998113989830017, 0.8604999780654907]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 71s 585ms/step - loss: 0.7845 - accuracy: 0.7013 - val_loss: 0.5142 - val_accuracy: 0.8072\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 77s 655ms/step - loss: 0.4573 - accuracy: 0.8332 - val_loss: 0.4265 - val_accuracy: 0.8442\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 79s 670ms/step - loss: 0.3807 - accuracy: 0.8616 - val_loss: 0.3612 - val_accuracy: 0.8673\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 81s 684ms/step - loss: 0.3350 - accuracy: 0.8792 - val_loss: 0.3300 - val_accuracy: 0.8819\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 81s 689ms/step - loss: 0.3048 - accuracy: 0.8904 - val_loss: 0.3239 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2867d6667f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (1,1), padding = 'valid',activation = 'elu' ,input_shape = [28,28,1]), # 1st Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 128 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'elu' ,input_shape = [28,28,1]), # 2nd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'elu' ,input_shape = [28,28,1]), # 3rd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(units = 128,activation = 'elu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 256,activation = 'elu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units = 256,activation = 'elu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 128,activation = 'elu'),\n",
    "        Dropout(0.10),\n",
    "        Dense(units = 10,activation = 'softmax')  \n",
    "                        \n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainX,trainy,epochs = 5,batch_size = 512,verbose = 1, validation_data=(testX,testy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3239 - accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3239170014858246, 0.882099986076355]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 83s 675ms/step - loss: 0.6944 - accuracy: 0.7480 - val_loss: 0.4474 - val_accuracy: 0.8320\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 84s 711ms/step - loss: 0.4184 - accuracy: 0.8494 - val_loss: 0.3750 - val_accuracy: 0.8623\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 71s 598ms/step - loss: 0.3542 - accuracy: 0.8737 - val_loss: 0.3578 - val_accuracy: 0.8749\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 69s 583ms/step - loss: 0.3152 - accuracy: 0.8875 - val_loss: 0.3296 - val_accuracy: 0.8813\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 68s 579ms/step - loss: 0.2848 - accuracy: 0.8974 - val_loss: 0.3267 - val_accuracy: 0.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2867d64b520>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (1,1), padding = 'valid',activation = 'selu' ,input_shape = [28,28,1]), # 1st Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 128 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'selu' ,input_shape = [28,28,1]), # 2nd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'selu' ,input_shape = [28,28,1]), # 3rd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(units = 128,activation = 'selu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 256,activation = 'selu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units = 256,activation = 'selu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 128,activation = 'selu'),\n",
    "        Dropout(0.10),\n",
    "        Dense(units = 10,activation = 'softmax')  \n",
    "                        \n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainX,trainy,epochs = 5,batch_size = 512,verbose = 1, validation_data=(testX,testy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3267 - accuracy: 0.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3266645073890686, 0.8851000070571899]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Different Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (1,1), padding = 'valid',activation = 'relu',input_shape = [28,28,1]), # 1st Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 128 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'relu',input_shape = [28,28,1]), # 2nd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Conv2D(filters = 64 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'relu',input_shape = [28,28,1]), # 3rd Layer\n",
    "        MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(units = 128,activation = 'relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 256,activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units = 256,activation = 'relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(units = 128,activation = 'relu'),\n",
    "        Dropout(0.10),\n",
    "        Dense(units = 10,activation = 'softmax')  \n",
    "                        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 79s 650ms/step - loss: 1.3289 - accuracy: 0.4711 - val_loss: 0.7293 - val_accuracy: 0.7161\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 64s 546ms/step - loss: 0.6922 - accuracy: 0.7388 - val_loss: 0.6006 - val_accuracy: 0.7812\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 68s 576ms/step - loss: 0.5391 - accuracy: 0.7994 - val_loss: 0.5752 - val_accuracy: 0.8007\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 66s 561ms/step - loss: 0.4604 - accuracy: 0.8319 - val_loss: 0.4658 - val_accuracy: 0.8219\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 67s 568ms/step - loss: 0.4038 - accuracy: 0.8533 - val_loss: 0.3740 - val_accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28632930790>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'RMSprop', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainX,trainy,epochs = 5,batch_size = 512,verbose = 1, validation_data=(testX,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3740 - accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37399888038635254, 0.8664000034332275]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 76s 619ms/step - loss: 0.3476 - accuracy: 0.8755 - val_loss: 0.3444 - val_accuracy: 0.8739\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 62s 527ms/step - loss: 0.3374 - accuracy: 0.8789 - val_loss: 0.3414 - val_accuracy: 0.8744\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 62s 523ms/step - loss: 0.3334 - accuracy: 0.8800 - val_loss: 0.3395 - val_accuracy: 0.8747\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 62s 524ms/step - loss: 0.3291 - accuracy: 0.8808 - val_loss: 0.3381 - val_accuracy: 0.8757\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 63s 535ms/step - loss: 0.3298 - accuracy: 0.8806 - val_loss: 0.3367 - val_accuracy: 0.8756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286329ba520>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'Adagrad', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainX,trainy,epochs = 5,batch_size = 512,verbose = 1, validation_data=(testX,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 14ms/step - loss: 0.3367 - accuracy: 0.8756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3367289900779724, 0.8755999803543091]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 68s 547ms/step - loss: 0.3281 - accuracy: 0.8829 - val_loss: 0.3209 - val_accuracy: 0.8846\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 64s 538ms/step - loss: 0.2970 - accuracy: 0.8928 - val_loss: 0.3020 - val_accuracy: 0.8928\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 62s 527ms/step - loss: 0.2855 - accuracy: 0.8986 - val_loss: 0.2912 - val_accuracy: 0.8955\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 63s 533ms/step - loss: 0.2704 - accuracy: 0.9037 - val_loss: 0.2887 - val_accuracy: 0.8959\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 64s 542ms/step - loss: 0.2590 - accuracy: 0.9085 - val_loss: 0.2810 - val_accuracy: 0.8993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2867bbcabb0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'Adamax', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainX,trainy,epochs = 5,batch_size = 512,verbose = 1, validation_data=(testX,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2810 - accuracy: 0.8993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2810269594192505, 0.8992999792098999]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying AlexNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(11,11),input_shape = (28, 28, 1), activation = 'relu'))                 \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size = (5,5), strides = (1,1), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size = (3,3), strides = (1,1), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size = (3,3), strides = (1,1), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), strides = (1,1), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Flatten()),\n",
    "model.add(Dense(units = 128,activation = 'relu')),\n",
    "model.add(Dropout(0.25)),\n",
    "model.add(Dense(units = 256,activation = 'relu')),\n",
    "model.add(Dropout(0.5)),\n",
    "model.add(Dense(units = 256,activation = 'relu')),\n",
    "model.add(Dropout(0.25)),\n",
    "model.add(Dense(units = 128,activation = 'relu')),\n",
    "model.add(Dropout(0.10)),\n",
    "model.add(Dense(units = 10,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 1090s 9s/step - loss: 0.6650 - accuracy: 0.7610 - val_loss: 3.4205 - val_accuracy: 0.1243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286180511f0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainX,trainy,epochs = 1,batch_size = 512,verbose = 1, validation_data=(testX,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 92ms/step - loss: 3.4205 - accuracy: 0.1243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.420466899871826, 0.12430000305175781]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95f57ecaf1e4684a97728584cbdcdcfb0a14de4fde6afb1e55592db96a99a5c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
